# API 프록시 

## 개요

OpenAI GPT-3.5 모델과 같은 API를 활용하는 서비스들을 위한 프록시 로드 밸런서 예시를 구현합니다. 

기본 목적은 API 요청을 효율적으로 관리하고, Rate limit 및 Retry 로직을 중앙에서 처리하여 서비스의 가용성과 효율성을 향상시키는 것입니다.

위 코드는 간단한 예시 구현입니다. 실제 프로덕션 환경에서는 자세한 구현이 필요합니다.

## 기능

* 재시도
* Rate limit 로드밸런싱 (RPM, BPM)
* 실시간 모니터링 
* 각 노드(API 공급자)에 독립적인 설정 


## 시작

> go run load_balancer.go
